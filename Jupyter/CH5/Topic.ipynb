{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from normalization import normalize_corpus\n",
    "import numpy as np\n",
    "\n",
    "toy_corpus = [\n",
    "    \"The fox jumps over the dog\",\n",
    "    \"The fox is very clever and quick\",\n",
    "    \"The dog is slow and lazy\",\n",
    "    \"The cat is smarter than the fox and the dog\",\n",
    "    \"Python is an excellent programming language\",\n",
    "    \"Java and Ruby are other programming languages\",\n",
    "    \"Python and Java are very popular programming languages\",\n",
    "    \"Python programs are smaller than Java programs\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lazy': 5, 'excellent': 9, 'small': 17, 'ruby': 14, 'python': 12, 'slow': 6, 'programming': 11, 'cat': 7, 'popular': 15, 'program': 16, 'smarter': 8, 'language': 10, 'dog': 0, 'quick': 4, 'jump': 2, 'fox': 1, 'clever': 3, 'java': 13}\n",
      "[[(0, 1), (1, 1), (2, 1)], [(1, 1), (3, 1), (4, 1)], [(0, 1), (5, 1), (6, 1)], [(0, 1), (1, 1), (7, 1), (8, 1)], [(9, 1), (10, 1), (11, 1), (12, 1)], [(10, 1), (11, 1), (13, 1), (14, 1)], [(10, 1), (11, 1), (12, 1), (13, 1), (15, 1)], [(12, 1), (13, 1), (16, 2), (17, 1)]]\n",
      "Topic #1\n",
      "0.459*\"language\" + 0.459*\"programming\" + 0.344*\"python\" + 0.344*\"java\" + 0.336*\"popular\" + 0.318*\"excellent\" + 0.318*\"ruby\" + 0.148*\"program\" + 0.074*\"small\" + -0.000*\"clever\"\n",
      "\n",
      "Topic #2\n",
      "-0.459*\"fox\" + -0.459*\"dog\" + -0.444*\"jump\" + -0.322*\"cat\" + -0.322*\"smarter\" + -0.208*\"slow\" + -0.208*\"lazy\" + -0.208*\"clever\" + -0.208*\"quick\" + -0.000*\"program\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norm_tokenized_corpus = normalize_corpus(toy_corpus, tokenize=True)\n",
    "norm_tokenized_corpus\n",
    "\n",
    "dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "print(dictionary.token2id)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in norm_tokenized_corpus]\n",
    "print(corpus)\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "total_topics = 2\n",
    "\n",
    "lsi = models.LsiModel(corpus_tfidf,\n",
    "                      id2word=dictionary,\n",
    "                      num_topics=total_topics)\n",
    "\n",
    "for index, topic in lsi.print_topics(total_topics):\n",
    "    print('Topic #'+str(index+1))\n",
    "    print(topic)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('language', 0.46), ('programming', 0.46), ('python', 0.34), ('java', 0.34), ('popular', 0.34)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('fox', -0.46), ('dog', -0.46), ('jump', -0.44), ('cat', -0.32), ('smarter', -0.32)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_topics_gensim(topic_model, total_topics=1,\n",
    "                        weight_threshold=0.0001,\n",
    "                        display_weights=False,\n",
    "                        num_terms=None):\n",
    "\n",
    "    for index in range(total_topics):\n",
    "        topic = topic_model.show_topic(index)\n",
    "        topic = [(word, round(wt,2))\n",
    "                 for word, wt in topic\n",
    "                 if abs(wt) >= weight_threshold]\n",
    "        if display_weights:\n",
    "            print('Topic #' + str(index + 1) + ' with weights')\n",
    "            print(topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print('Topic #' + str(index + 1) + ' without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print(tw[:num_terms] if num_terms else tw)\n",
    "        print()\n",
    "\n",
    "\n",
    "print_topics_gensim(topic_model=lsi,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=5,\n",
    "                    display_weights=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI custom built topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_feature_matrix, low_rank_svd\n",
    "\n",
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(\n",
    "    norm_corpus,\n",
    "    feature_type='tfidf'\n",
    ")\n",
    "\n",
    "td_matrix = tfidf_matrix.transpose()\n",
    "\n",
    "td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "\n",
    "total_topics = 2\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "u, s, vt = low_rank_svd(td_matrix, singular_count=total_topics)\n",
    "weights = u.transpose() * s[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['dog', 'fox', 'jump', 'smarter', 'cat', 'quick', 'clever', 'slow', 'lazy']\n",
      "\n",
      "Topic #2 without weights\n",
      "['programming', 'language', 'python', 'java', 'popular', 'excellent', 'ruby', 'program']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_topics_terms_weights(weights, feature_names):\n",
    "    feature_names = np.array(feature_names)\n",
    "    sorted_indices = np.array([list(row[::-1])\n",
    "                           for row\n",
    "                           in np.argsort(np.abs(weights))])\n",
    "    sorted_weights = np.array([list(wt[index])\n",
    "                               for wt, index\n",
    "                               in zip(weights,sorted_indices)])\n",
    "    sorted_terms = np.array([list(feature_names[row])\n",
    "                             for row\n",
    "                             in sorted_indices])\n",
    "\n",
    "    topics = [np.vstack((terms.T,\n",
    "                     term_weights.T)).T\n",
    "              for terms, term_weights\n",
    "              in zip(sorted_terms, sorted_weights)]\n",
    "\n",
    "    return topics\n",
    "\n",
    "\n",
    "def print_topics_udf(topics, total_topics=1,\n",
    "                     weight_threshold=0.0001,\n",
    "                     display_weights=False,\n",
    "                     num_terms=None):\n",
    "\n",
    "    for index in range(total_topics):\n",
    "        topic = topics[index]\n",
    "        topic = [(term, float(wt))\n",
    "                 for term, wt in topic]\n",
    "        topic = [(word, round(wt,2))\n",
    "                 for word, wt in topic\n",
    "                 if abs(wt) >= weight_threshold]\n",
    "\n",
    "        if display_weights:\n",
    "            print('Topic #' + str(index + 1) + ' with weights')\n",
    "            print(topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print('Topic #' + str(index + 1) + ' without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print(tw[:num_terms] if num_terms else tw)\n",
    "        print()\n",
    "\n",
    "\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 weight_threshold=0.15,\n",
    "                 display_weights=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('language', 0.08), ('programming', 0.08), ('popular', 0.07), ('python', 0.07), ('java', 0.07)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('dog', 0.08), ('jump', 0.07), ('program', 0.07), ('fox', 0.07), ('cat', 0.06)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_lsi_model_gensim(corpus, total_topics=2):\n",
    "\n",
    "    norm_tokenized_corpus = normalize_corpus(corpus, tokenize=True)\n",
    "    dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "    mapped_corpus = [dictionary.doc2bow(text)\n",
    "                     for text in norm_tokenized_corpus]\n",
    "    tfidf = models.TfidfModel(mapped_corpus)\n",
    "    corpus_tfidf = tfidf[mapped_corpus]\n",
    "    lsi = models.LsiModel(corpus_tfidf,\n",
    "                          id2word=dictionary,\n",
    "                          num_topics=total_topics)\n",
    "    return lsi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_lda_model_gensim(corpus, total_topics=2):\n",
    "\n",
    "    norm_tokenized_corpus = normalize_corpus(corpus, tokenize=True)\n",
    "    dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "    mapped_corpus = [dictionary.doc2bow(text)\n",
    "                     for text in norm_tokenized_corpus]\n",
    "    tfidf = models.TfidfModel(mapped_corpus)\n",
    "    corpus_tfidf = tfidf[mapped_corpus]\n",
    "    lda = models.LdaModel(corpus_tfidf,\n",
    "                          id2word=dictionary,\n",
    "                          iterations=1000,\n",
    "                          num_topics=total_topics)\n",
    "    return lda\n",
    "\n",
    "\n",
    "\n",
    "lda_gensim = train_lda_model_gensim(toy_corpus,\n",
    "                                    total_topics=2)\n",
    "\n",
    "print_topics_gensim(topic_model=lda_gensim,\n",
    "                    total_topics=2,\n",
    "                    num_terms=5,\n",
    "                    display_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('fox', 1.86), ('dog', 1.86), ('jump', 1.19), ('clever', 1.12), ('quick', 1.12), ('lazy', 1.12), ('slow', 1.12), ('cat', 1.06)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('programming', 1.8), ('language', 1.8), ('java', 1.64), ('python', 1.64), ('program', 1.3), ('ruby', 1.11), ('excellent', 1.11), ('popular', 1.06)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus,\n",
    "                                    feature_type='tfidf')\n",
    "total_topics = 2\n",
    "lda = LatentDirichletAllocation(n_components=total_topics,\n",
    "                                max_iter=1000,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=42)\n",
    "lda.fit(tfidf_matrix)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = lda.components_\n",
    "\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=8,\n",
    "                 display_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('programming', 0.55), ('language', 0.55), ('python', 0.4), ('java', 0.4), ('popular', 0.24), ('excellent', 0.23), ('ruby', 0.23), ('program', 0.09), ('small', 0.03)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('dog', 0.57), ('fox', 0.57), ('jump', 0.35), ('smarter', 0.26), ('cat', 0.26), ('quick', 0.13), ('slow', 0.13), ('clever', 0.13), ('lazy', 0.13)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus,\n",
    "                                    feature_type='tfidf')\n",
    "total_topics = 2\n",
    "nmf = NMF(n_components=total_topics,\n",
    "          random_state=42, alpha=.1, l1_ratio=.5)\n",
    "nmf.fit(tfidf_matrix)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = nmf.components_\n",
    "\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=None,\n",
    "                 display_weights=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I base the value of a game on the amount of enjoyable gameplay I can get out of it and this one was definitely worth the price!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CORPUS = pd.read_csv('amazon_skyrim_reviews.csv')\n",
    "CORPUS = np.array(CORPUS['Reviews'])\n",
    "\n",
    "# view sample review\n",
    "print(CORPUS[12])\n",
    "\n",
    "total_topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['skyrim', 'one', 'quest', 'like', 'play', 'oblivion', 'go', 'get', 'time', 'level']\n",
      "\n",
      "Topic #2 without weights\n",
      "['recommend', 'love', 'ever', 'best', 'great', 'level', 'highly', 'buy', 'play', 'elder']\n",
      "\n",
      "Topic #3 without weights\n",
      "['recommend', 'fun', 'highly', 'love', 'ever', 'wonderful', 'scroll', 'elder', 'series', 'definitely']\n",
      "\n",
      "Topic #4 without weights\n",
      "['fun', 'scroll', 'elder', 'recommend', 'highly', 'wonderful', 'series', 'graphic', 'fan', 'everyone']\n",
      "\n",
      "Topic #5 without weights\n",
      "['fun', 'love', 'scroll', 'elder', '5', 'highly', 'dont', 'hour', 'hundred', 'series']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsi_gensim = train_lsi_model_gensim(CORPUS,\n",
    "                                    total_topics=total_topics)\n",
    "print_topics_gensim(topic_model=lsi_gensim,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=10,\n",
    "                    display_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['love', 'amazing', 'dont', 'ever', 'hundred', 'elder', 'say', 'system', 'gameplay', 'scroll']\n",
      "\n",
      "Topic #2 without weights\n",
      "['skyrim', 'play', 'one', 'best', 'great', 'ever', 'rpg', 'buy', 'like', 'character']\n",
      "\n",
      "Topic #3 without weights\n",
      "['good', 'one', 'play', 'really', 'love', 'time', 'make', 'want', 'like', 'highly']\n",
      "\n",
      "Topic #4 without weights\n",
      "['quest', 'get', 'good', 'thing', 'oblivion', 'one', 'like', 'time', 'go', 'much']\n",
      "\n",
      "Topic #5 without weights\n",
      "['fun', 'play', 'get', 'long', 'great', 'buy', 'hour', 'love', 'much', 'quest']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_gensim = train_lda_model_gensim(CORPUS,\n",
    "                                    total_topics=total_topics)\n",
    "print_topics_gensim(topic_model=lda_gensim,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=10,\n",
    "                    display_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_corpus = normalize_corpus(CORPUS)\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus,\n",
    "                                    feature_type='tfidf')\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['estatic', 'booklet', 'wonder4ful', 'electricity', 'heat', 'trhats', 'amazingly', 'interfere', 'chirstmas', '12yr']\n",
      "\n",
      "Topic #2 without weights\n",
      "['game', 'play', 'get', 'one', 'skyrim', 'great', 'like', 'time', 'quest', 'much']\n",
      "\n",
      "Topic #3 without weights\n",
      "['de', 'cr√©dito', 'pagar', 'momento', 'compras', 'responsabilidad', 'para', 'recomiendo', 'futuras', 'skyrimseguridad']\n",
      "\n",
      "Topic #4 without weights\n",
      "['booklet', 'estatic', 'wonder4ful', 'electricity', 'heat', 'trhats', 'amazingly', 'interfere', 'chirstmas', '12yr']\n",
      "\n",
      "Topic #5 without weights\n",
      "['estatic', 'booklet', 'wonder4ful', 'electricity', 'trhats', 'heat', 'amazingly', 'interfere', 'chirstmas', '12yr']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=total_topics,\n",
    "                                max_iter=1000,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=10.,\n",
    "                                random_state=42)\n",
    "lda.fit(tfidf_matrix)\n",
    "weights = lda.components_\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=10,\n",
    "                 display_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['game', 'get', 'skyrim', 'play', 'time', 'quest', 'like', 'one', 'go', 'much']\n",
      "\n",
      "Topic #2 without weights\n",
      "['game', 'recommend', 'love', 'great', 'highly', 'play', 'wonderful', 'like', 'would', 'graphic']\n",
      "\n",
      "Topic #3 without weights\n",
      "['scroll', 'elder', 'series', 'always', 'love', 'pass', 'franchise', 'buy', 'game', 'far']\n",
      "\n",
      "Topic #4 without weights\n",
      "['ever', 'best', 'game', 'play', 'rpg', 'one', 'ive', 'hour', 'great', 'definitely']\n",
      "\n",
      "Topic #5 without weights\n",
      "['fun', 'game', 'much', 'graphic', 'improvement', 'mission', 'expect', 'see', 'hour', 'couple']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=total_topics,\n",
    "          random_state=42, alpha=.1, l1_ratio=.5)\n",
    "nmf.fit(tfidf_matrix)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = nmf.components_\n",
    "\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=10,\n",
    "                 display_weights=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
